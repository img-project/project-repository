{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version check :  2.0.0\n",
      "gpu check :  True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "print(\"tensorflow version check : \", tf.__version__)\n",
    "print(\"gpu check : \",tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 불러오기\n",
    "### 이미지 파일들을 그대로 불러오면 용량이 너무 크니 경로를 지정하여 다룸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'workspace/img_project/before_folder/image_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = pathlib.Path(data_dir+'/Training')\n",
    "private_test_dir = pathlib.Path(data_dir+'/PrivateTest')\n",
    "public_test_dir = pathlib.Path(data_dir+'/PublicTest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709\n",
      "3589\n",
      "3589\n"
     ]
    }
   ],
   "source": [
    "# 각 경로 별 데이터 갯수 확인\n",
    "print(len(list(train_dir.glob('*/*.jpg'))))\n",
    "print(len(list(public_test_dir.glob('*/*.jpg'))))\n",
    "print(len(list(private_test_dir.glob('*/*.jpg'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataset 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(train_dir/'*/*'))\n",
    "val_list_ds = tf.data.Dataset.list_files(str(public_test_dir/'*/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'workspace\\\\img_project\\\\before_folder\\\\image_train\\\\Training\\\\Fear\\\\17369.jpg'\n",
      "b'workspace\\\\img_project\\\\before_folder\\\\image_train\\\\Training\\\\Sad\\\\14899.jpg'\n",
      "b'workspace\\\\img_project\\\\before_folder\\\\image_train\\\\Training\\\\Sad\\\\21100.jpg'\n",
      "b'workspace\\\\img_project\\\\before_folder\\\\image_train\\\\Training\\\\Surprise\\\\22017.jpg'\n",
      "b'workspace\\\\img_project\\\\before_folder\\\\image_train\\\\Training\\\\Fear\\\\15584.jpg'\n"
     ]
    }
   ],
   "source": [
    "#확인하기\n",
    "for f in list_ds.take(5) : \n",
    "    print(f.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data labeling을 위한 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS_NAMES = np.array([item.name for item in train_dir.glob('*')])\n",
    "\n",
    "CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Angry': 0, 'Disgust': 1, 'Fear': 2, 'Happy': 3, 'Neutral': 4, 'Sad': 5, 'Surprise': 6}\n"
     ]
    }
   ],
   "source": [
    "CLASS_NAME_TO_ID = {}\n",
    "for id, name in enumerate(CLASS_NAMES):\n",
    "    CLASS_NAME_TO_ID[name] = id\n",
    "    \n",
    "print(CLASS_NAME_TO_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise'] [0, 1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "keys = list(CLASS_NAME_TO_ID.keys())\n",
    "ids = list(CLASS_NAME_TO_ID.values())\n",
    "print(keys,ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = tf.lookup.StaticHashTable(\n",
    "    initializer= tf.lookup.KeyValueTensorInitializer(\n",
    "    keys= tf.constant(keys),\n",
    "    values=tf.constant(ids),),\n",
    "    default_value=tf.constant(-1),\n",
    "    name=\"class_weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 96\n",
    "IMG_WIDTH = 96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data labeling을 위한 함수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path) :\n",
    "    parts = tf.strings.split(file_path, '\\\\')\n",
    "    return table.lookup(parts[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "    img = tf.image.decode_jpeg(img,channels=1)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return tf.image.resize(img,[IMG_WIDTH,IMG_HEIGHT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### labeling 된 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_ds = list_ds.shuffle(10000).map(process_path, num_parallel_calls=AUTOTUNE).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape :  (32, 96, 96, 1)\n",
      "Label :  [4 6 3 6 3 0 3 5 4 3 4 5 4 4 0 4 0 5 4 3 5 5 2 0 3 3 3 6 3 5 0 0]\n"
     ]
    }
   ],
   "source": [
    "for image, label in labeled_ds.take(1) :\n",
    "    print(\"image shape : \", image.numpy().shape)\n",
    "    print(\"Label : \", label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 만들기  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(96, 96,1), name='img')\n",
    "\n",
    "feature = tf.keras.layers.Conv2D(8, 3, padding = 'same', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3))(inputs)\n",
    "feature = tf.keras.layers.BatchNormalization()(feature)\n",
    "feature = tf.keras.layers.ReLU()(feature)\n",
    "feature = tf.keras.layers.Conv2D(8, 3, padding='same')(feature)\n",
    "feature = tf.keras.layers.BatchNormalization()(feature)\n",
    "feature = tf.keras.layers.ReLU()(feature)\n",
    "feature = tf.keras.layers.Conv2D(8, 3, padding='same')(feature)\n",
    "feature = tf.keras.layers.BatchNormalization()(feature)\n",
    "feature = tf.keras.layers.ReLU()(feature)\n",
    "feature = tf.keras.layers.MaxPooling2D()(feature)\n",
    "feature = tf.keras.layers.Dropout(0.25)(feature)\n",
    "\n",
    "\n",
    "feature = tf.keras.layers.Conv2D(32, 3, padding='same')(feature)\n",
    "feature = tf.keras.layers.BatchNormalization()(feature)\n",
    "feature = tf.keras.layers.ReLU()(feature)\n",
    "feature = tf.keras.layers.Conv2D(32, 3, padding='same')(feature)\n",
    "feature = tf.keras.layers.BatchNormalization()(feature)\n",
    "feature = tf.keras.layers.ReLU()(feature)\n",
    "feature = tf.keras.layers.Conv2D(32, 3, padding='same')(feature)\n",
    "feature = tf.keras.layers.BatchNormalization()(feature)\n",
    "feature = tf.keras.layers.ReLU()(feature)\n",
    "feature = tf.keras.layers.MaxPooling2D()(feature)\n",
    "feature = tf.keras.layers.Dropout(0.25)(feature)\n",
    "\n",
    "\n",
    "feature = tf.keras.layers.Conv2D(64, 3, padding='same')(feature)\n",
    "feature = tf.keras.layers.BatchNormalization()(feature)\n",
    "feature = tf.keras.layers.ReLU()(feature)\n",
    "feature = tf.keras.layers.Conv2D(64, 3, padding='same')(feature)\n",
    "feature = tf.keras.layers.BatchNormalization()(feature)\n",
    "feature = tf.keras.layers.ReLU()(feature)\n",
    "feature = tf.keras.layers.Conv2D(64, 3, padding='same')(feature)\n",
    "feature = tf.keras.layers.BatchNormalization()(feature)\n",
    "feature = tf.keras.layers.ReLU()(feature)\n",
    "feature = tf.keras.layers.MaxPooling2D()(feature)\n",
    "feature = tf.keras.layers.Dropout(0.25)(feature)\n",
    "\n",
    "feature = tf.keras.layers.Conv2D(128, 3, padding='same')(feature)\n",
    "feature = tf.keras.layers.BatchNormalization()(feature)\n",
    "feature = tf.keras.layers.ReLU()(feature)\n",
    "feature = tf.keras.layers.Conv2D(128, 3, padding='same')(feature)\n",
    "feature = tf.keras.layers.BatchNormalization()(feature)\n",
    "feature = tf.keras.layers.ReLU()(feature)\n",
    "feature = tf.keras.layers.Conv2D(128, 3, padding='same')(feature)\n",
    "feature = tf.keras.layers.BatchNormalization()(feature)\n",
    "feature = tf.keras.layers.ReLU()(feature)\n",
    "feature = tf.keras.layers.MaxPooling2D()(feature)\n",
    "feature = tf.keras.layers.Dropout(0.25)(feature)\n",
    "\n",
    "#feature = tf.keras.layers.Flatten()(feature)\n",
    "feature = tf.keras.layers.GlobalAveragePooling2D()(feature)\n",
    "feature = tf.keras.layers.Dense(256, activation='relu')(feature)\n",
    "feature = tf.keras.layers.Dense(128, activation='relu')(feature)\n",
    "outputs = tf.keras.layers.Dense(7, activation='softmax')(feature)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 96, 96, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 96, 96, 8)         80        \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 96, 96, 8)         32        \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 96, 96, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 96, 96, 8)         584       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 96, 8)         32        \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 96, 96, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 96, 96, 8)         584       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 96, 96, 8)         32        \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 96, 96, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 48, 48, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 48, 48, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 48, 48, 32)        2336      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_9 (ReLU)               (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_10 (ReLU)              (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_11 (ReLU)              (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 553,063\n",
      "Trainable params: 551,671\n",
      "Non-trainable params: 1,392\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "             loss = tf.keras.losses.sparse_categorical_crossentropy,\n",
    "             metrics=[tf.keras.metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "-----------------Training Start-----------------\n",
      "Epoch 1/60\n",
      "898/898 [==============================] - 31s 35ms/step - loss: 1.6701 - sparse_categorical_accuracy: 0.3183\n",
      "Epoch 2/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 1.3666 - sparse_categorical_accuracy: 0.4769\n",
      "Epoch 3/60\n",
      "898/898 [==============================] - 22s 25ms/step - loss: 1.2645 - sparse_categorical_accuracy: 0.5172\n",
      "Epoch 4/60\n",
      "898/898 [==============================] - 22s 25ms/step - loss: 1.1995 - sparse_categorical_accuracy: 0.5396\n",
      "Epoch 5/60\n",
      "898/898 [==============================] - 22s 25ms/step - loss: 1.1472 - sparse_categorical_accuracy: 0.5619\n",
      "Epoch 6/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 1.1089 - sparse_categorical_accuracy: 0.5780\n",
      "Epoch 7/60\n",
      "898/898 [==============================] - 22s 25ms/step - loss: 1.0800 - sparse_categorical_accuracy: 0.5881\n",
      "Epoch 8/60\n",
      "898/898 [==============================] - 22s 25ms/step - loss: 1.0452 - sparse_categorical_accuracy: 0.6020\n",
      "Epoch 9/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 1.0178 - sparse_categorical_accuracy: 0.6151\n",
      "Epoch 10/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.9917 - sparse_categorical_accuracy: 0.6256\n",
      "Epoch 11/60\n",
      "898/898 [==============================] - 22s 25ms/step - loss: 0.9633 - sparse_categorical_accuracy: 0.6383\n",
      "Epoch 12/60\n",
      "898/898 [==============================] - 22s 25ms/step - loss: 0.9408 - sparse_categorical_accuracy: 0.6471\n",
      "Epoch 13/60\n",
      "898/898 [==============================] - 22s 25ms/step - loss: 0.9271 - sparse_categorical_accuracy: 0.6506 2s - loss: 0.9286\n",
      "Epoch 14/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.8995 - sparse_categorical_accuracy: 0.6604 0s - loss: 0.8996 - sparse_categorical_accuracy: 0.\n",
      "Epoch 15/60\n",
      "898/898 [==============================] - 22s 25ms/step - loss: 0.8826 - sparse_categorical_accuracy: 0.6693\n",
      "Epoch 16/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.8570 - sparse_categorical_accuracy: 0.6786\n",
      "Epoch 17/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.8345 - sparse_categorical_accuracy: 0.6904\n",
      "Epoch 18/60\n",
      "898/898 [==============================] - 22s 25ms/step - loss: 0.8173 - sparse_categorical_accuracy: 0.6926\n",
      "Epoch 19/60\n",
      "898/898 [==============================] - 22s 25ms/step - loss: 0.7980 - sparse_categorical_accuracy: 0.7018\n",
      "Epoch 20/60\n",
      "898/898 [==============================] - 22s 25ms/step - loss: 0.7871 - sparse_categorical_accuracy: 0.7063\n",
      "Epoch 21/60\n",
      "898/898 [==============================] - 22s 25ms/step - loss: 0.7600 - sparse_categorical_accuracy: 0.7179\n",
      "Epoch 22/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.7397 - sparse_categorical_accuracy: 0.7235\n",
      "Epoch 23/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.7236 - sparse_categorical_accuracy: 0.7324\n",
      "Epoch 24/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.7000 - sparse_categorical_accuracy: 0.7398\n",
      "Epoch 25/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.6905 - sparse_categorical_accuracy: 0.7412\n",
      "Epoch 26/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.6737 - sparse_categorical_accuracy: 0.7477\n",
      "Epoch 27/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.6615 - sparse_categorical_accuracy: 0.7545\n",
      "Epoch 28/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.6372 - sparse_categorical_accuracy: 0.7622\n",
      "Epoch 29/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.6257 - sparse_categorical_accuracy: 0.7691\n",
      "Epoch 30/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.6066 - sparse_categorical_accuracy: 0.7778\n",
      "Epoch 31/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.5954 - sparse_categorical_accuracy: 0.7834\n",
      "Epoch 32/60\n",
      "898/898 [==============================] - 22s 25ms/step - loss: 0.5815 - sparse_categorical_accuracy: 0.7859\n",
      "Epoch 33/60\n",
      "898/898 [==============================] - 22s 25ms/step - loss: 0.5659 - sparse_categorical_accuracy: 0.7903\n",
      "Epoch 34/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.5501 - sparse_categorical_accuracy: 0.7972\n",
      "Epoch 35/60\n",
      "898/898 [==============================] - 22s 25ms/step - loss: 0.5370 - sparse_categorical_accuracy: 0.8030 2s - loss: 0.5323 - \n",
      "Epoch 36/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.5294 - sparse_categorical_accuracy: 0.8063\n",
      "Epoch 37/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.5158 - sparse_categorical_accuracy: 0.8101\n",
      "Epoch 38/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.5023 - sparse_categorical_accuracy: 0.8107\n",
      "Epoch 39/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.4866 - sparse_categorical_accuracy: 0.8211\n",
      "Epoch 40/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.4751 - sparse_categorical_accuracy: 0.8273\n",
      "Epoch 41/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.4632 - sparse_categorical_accuracy: 0.8308\n",
      "Epoch 42/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.4542 - sparse_categorical_accuracy: 0.8332\n",
      "Epoch 43/60\n",
      "898/898 [==============================] - 22s 25ms/step - loss: 0.4414 - sparse_categorical_accuracy: 0.8394\n",
      "Epoch 44/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.4304 - sparse_categorical_accuracy: 0.8426\n",
      "Epoch 45/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.4237 - sparse_categorical_accuracy: 0.8467 0s - loss: 0.4233 - sparse_categorical_accuracy: 0\n",
      "Epoch 46/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.4122 - sparse_categorical_accuracy: 0.8474\n",
      "Epoch 47/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.4035 - sparse_categorical_accuracy: 0.8529\n",
      "Epoch 48/60\n",
      "898/898 [==============================] - 22s 25ms/step - loss: 0.3975 - sparse_categorical_accuracy: 0.8534\n",
      "Epoch 49/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.3915 - sparse_categorical_accuracy: 0.8564\n",
      "Epoch 50/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.3823 - sparse_categorical_accuracy: 0.8608\n",
      "Epoch 51/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.3701 - sparse_categorical_accuracy: 0.8639\n",
      "Epoch 52/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.3639 - sparse_categorical_accuracy: 0.8668\n",
      "Epoch 53/60\n",
      "898/898 [==============================] - 22s 25ms/step - loss: 0.3590 - sparse_categorical_accuracy: 0.8706\n",
      "Epoch 54/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.3475 - sparse_categorical_accuracy: 0.8727\n",
      "Epoch 55/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.3464 - sparse_categorical_accuracy: 0.8737\n",
      "Epoch 56/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.3351 - sparse_categorical_accuracy: 0.8791\n",
      "Epoch 57/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.3334 - sparse_categorical_accuracy: 0.8765\n",
      "Epoch 58/60\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.3235 - sparse_categorical_accuracy: 0.8828\n",
      "Epoch 59/60\n",
      "898/898 [==============================] - 22s 25ms/step - loss: 0.3211 - sparse_categorical_accuracy: 0.8824\n",
      "Epoch 60/60\n",
      "898/898 [==============================] - 22s 25ms/step - loss: 0.3132 - sparse_categorical_accuracy: 0.8855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20f887a8948>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(model.trainable_variables))\n",
    "\n",
    "print(\"-----------------Training Start-----------------\")\n",
    "model.fit(labeled_ds,epochs= 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_parallel_calls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-433715ee5c18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mval_labeled_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_list_ds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'num_parallel_calls' is not defined"
     ]
    }
   ],
   "source": [
    "val_labeled_ds = val_list_ds.map(process_path,num_parallel_calls=AUTOTUNE).batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in val_labeled_ds.take(1):\n",
    "  print(i[0].shape, i[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(val_labeled_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
