{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version check :  2.0.0\n",
      "gpu check :  True\n"
     ]
    }
   ],
   "source": [
    "print(\"tensorflow version check : \", tf.__version__)\n",
    "print(\"gpu check : \",tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 불러오기\n",
    "### 이미지 파일들을 그대로 불러오면 용량이 너무 크니 경로를 지정하여 다룸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = pathlib.Path('../../before_folder/image_train/Training')\n",
    "private_test_dir = pathlib.Path('../../before_folder/image_train/PrivateTest')\n",
    "public_test_dir = pathlib.Path('../../before_folder/image_train/PublicTest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28708\n",
      "3589\n",
      "3589\n"
     ]
    }
   ],
   "source": [
    "# 각 경로 별 데이터 갯수 확인\n",
    "print(len(list(train_dir.glob('*/*.jpg'))))\n",
    "print(len(list(public_test_dir.glob('*/*.jpg'))))\n",
    "print(len(list(private_test_dir.glob('*/*.jpg'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataset 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(train_dir/'*/*.jpg'))\n",
    "val_list_ds = tf.data.Dataset.list_files(str(public_test_dir/'*/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'..\\\\..\\\\before_folder\\\\image_train\\\\Training\\\\Fear\\\\11916.jpg'\n",
      "b'..\\\\..\\\\before_folder\\\\image_train\\\\Training\\\\Neutral\\\\12468.jpg'\n",
      "b'..\\\\..\\\\before_folder\\\\image_train\\\\Training\\\\Sad\\\\3265.jpg'\n",
      "b'..\\\\..\\\\before_folder\\\\image_train\\\\Training\\\\Neutral\\\\21528.jpg'\n",
      "b'..\\\\..\\\\before_folder\\\\image_train\\\\Training\\\\Fear\\\\2177.jpg'\n"
     ]
    }
   ],
   "source": [
    "#확인하기\n",
    "for f in list_ds.take(5) : \n",
    "    print(f.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data labeling을 위한 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS_NAMES = np.array([item.name for item in train_dir.glob('*')])\n",
    "\n",
    "CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Angry': 0, 'Disgust': 1, 'Fear': 2, 'Happy': 3, 'Neutral': 4, 'Sad': 5, 'Surprise': 6}\n"
     ]
    }
   ],
   "source": [
    "CLASS_NAME_TO_ID = {}\n",
    "for id, name in enumerate(CLASS_NAMES):\n",
    "    CLASS_NAME_TO_ID[name] = id\n",
    "    \n",
    "print(CLASS_NAME_TO_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise'] [0, 1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "keys = list(CLASS_NAME_TO_ID.keys())\n",
    "ids = list(CLASS_NAME_TO_ID.values())\n",
    "print(keys,ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = tf.lookup.StaticHashTable(\n",
    "    initializer= tf.lookup.KeyValueTensorInitializer(\n",
    "    keys= tf.constant(keys),\n",
    "    values=tf.constant(ids),),\n",
    "    default_value=tf.constant(-1),\n",
    "    name=\"class_weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "IMG_HEIGHT = 96\n",
    "IMG_WIDTH = 96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data labeling을 위한 함수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path) :\n",
    "    parts = tf.strings.split(file_path, '\\\\')\n",
    "    return table.lookup(parts[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "    img = tf.image.decode_jpeg(img,channels=1)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return tf.image.resize(img,[IMG_WIDTH,IMG_HEIGHT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### labeling 된 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_ds = list_ds.shuffle(10000).map(process_path, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE)\n",
    "val_labeled_ds = val_list_ds.map(process_path,num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape :  (64, 96, 96, 1)\n",
      "Label :  [6 4 4 5 0 4 6 0 3 5 5 0 5 2 2 2 3 3 4 5 3 5 0 0 3 2 6 0 2 2 4 3 0 2 2 0 2\n",
      " 5 3 4 6 2 0 3 4 0 5 2 2 6 4 3 4 0 5 4 6 5 5 5 6 5 2 4]\n",
      "val_img_shape :  (64, 96, 96, 1)\n"
     ]
    }
   ],
   "source": [
    "for image, label in labeled_ds.take(1) :\n",
    "    print(\"image shape : \", image.numpy().shape)\n",
    "    print(\"Label : \", label.numpy())\n",
    "    \n",
    "for i in val_labeled_ds.take(1):\n",
    "    print('val_img_shape : ',i[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 만들기  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model() :\n",
    "    inputs = keras.Input(shape=(96, 96,1), name='img')\n",
    "\n",
    "    feature = tf.keras.layers.Conv2D(96, 3, padding = 'same', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3))(inputs)\n",
    "    feature = tf.keras.layers.BatchNormalization()(feature)\n",
    "    feature = tf.keras.layers.ReLU()(feature)\n",
    "    feature = tf.keras.layers.Conv2D(16, 3, padding='same')(feature)\n",
    "    feature = tf.keras.layers.BatchNormalization()(feature)\n",
    "    feature = tf.keras.layers.ReLU()(feature)\n",
    "    feature = tf.keras.layers.MaxPooling2D()(feature)\n",
    "    feature = tf.keras.layers.Dropout(0.2)(feature)\n",
    "\n",
    "    feature = tf.keras.layers.Conv2D(32, 3, padding='same')(feature)\n",
    "    feature = tf.keras.layers.BatchNormalization()(feature)\n",
    "    feature = tf.keras.layers.ReLU()(feature)\n",
    "    feature = tf.keras.layers.MaxPooling2D()(feature)\n",
    "    feature = tf.keras.layers.Dropout(0.2)(feature)\n",
    "\n",
    "    feature = tf.keras.layers.Conv2D(64, 3, padding='same')(feature)\n",
    "    feature = tf.keras.layers.BatchNormalization()(feature)\n",
    "    feature = tf.keras.layers.ReLU()(feature)\n",
    "    feature = tf.keras.layers.MaxPooling2D()(feature)\n",
    "    feature = tf.keras.layers.Dropout(0.2)(feature)\n",
    "    \n",
    "    feature = tf.keras.layers.Conv2D(16, 3, padding='same')(feature)\n",
    "    feature = tf.keras.layers.BatchNormalization()(feature)\n",
    "    feature = tf.keras.layers.ReLU()(feature)\n",
    "    feature = tf.keras.layers.MaxPooling2D()(feature)\n",
    "    feature = tf.keras.layers.Dropout(0.2)(feature)\n",
    "    \n",
    "    #feature = tf.keras.layers.Flatten()(feature)\n",
    "    feature = tf.keras.layers.GlobalAveragePooling2D()(feature)\n",
    "    feature = tf.keras.layers.Dense(96, activation='relu')(feature)\n",
    "    feature = tf.keras.layers.Dense(32, activation='relu')(feature)\n",
    "    outputs = tf.keras.layers.Dense(7, activation='softmax')(feature)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len(list(list_ds))\n",
    "val_len = len(list(val_list_ds))\n",
    "\n",
    "steps_per_epoch = train_len // BATCH_SIZE\n",
    "validation_steps = val_len // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"../../before_folder/model_save/cp-{epoch:04d}-{val_loss:.2f}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 200\n",
    "learning_rate = 0.0001\n",
    "\n",
    "def train_model(model):\n",
    "    \n",
    "    model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate = learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                                   period=5)\n",
    "    \n",
    "    history = model.fit(labeled_ds.repeat(),\n",
    "                        epochs=EPOCH,\n",
    "                        steps_per_epoch = steps_per_epoch,\n",
    "                        validation_data = val_labeled_ds,\n",
    "                        validation_steps = validation_steps,\n",
    "                        callbacks = [model_checkpoint_callback])\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train for 448 steps, validate for 56 steps\n",
      "Epoch 1/200\n",
      "448/448 [==============================] - 31s 68ms/step - loss: 1.1174 - accuracy: 0.5753 - val_loss: 1.2048 - val_accuracy: 0.5312.1168 - \n",
      "Epoch 2/200\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 1.1089 - accuracy: 0.5797 - val_loss: 1.1538 - val_accuracy: 0.5675\n",
      "Epoch 3/200\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 1.1159 - accuracy: 0.5766 - val_loss: 1.1513 - val_accuracy: 0.5611\n",
      "Epoch 4/200\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 1.1122 - accuracy: 0.5770 - val_loss: 1.3189 - val_accuracy: 0.5109\n",
      "Epoch 5/200\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 1.1046 - accuracy: 0.5804 - val_loss: 1.1858 - val_accuracy: 0.5472\n",
      "Epoch 6/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.1100 - accuracy: 0.5752 - val_loss: 1.2178 - val_accuracy: 0.5257\n",
      "Epoch 7/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.1042 - accuracy: 0.5840 - val_loss: 1.1968 - val_accuracy: 0.5446\n",
      "Epoch 8/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.1066 - accuracy: 0.5819 - val_loss: 1.1567 - val_accuracy: 0.5631\n",
      "Epoch 9/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.1032 - accuracy: 0.5802 - val_loss: 1.1455 - val_accuracy: 0.5642\n",
      "Epoch 10/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.1029 - accuracy: 0.5820 - val_loss: 1.1652 - val_accuracy: 0.5552\n",
      "Epoch 11/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0993 - accuracy: 0.5832 - val_loss: 1.2200 - val_accuracy: 0.5396\n",
      "Epoch 12/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.1036 - accuracy: 0.5846 - val_loss: 1.2822 - val_accuracy: 0.5335\n",
      "Epoch 13/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0990 - accuracy: 0.5845 - val_loss: 1.1925 - val_accuracy: 0.5539\n",
      "Epoch 14/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.1081 - accuracy: 0.5799 - val_loss: 1.1695 - val_accuracy: 0.5575\n",
      "Epoch 15/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0984 - accuracy: 0.5813 - val_loss: 1.1462 - val_accuracy: 0.5619\n",
      "Epoch 16/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.1000 - accuracy: 0.5812 - val_loss: 1.1578 - val_accuracy: 0.5544\n",
      "Epoch 17/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.1000 - accuracy: 0.5838 - val_loss: 1.1357 - val_accuracy: 0.5675\n",
      "Epoch 18/200\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 1.0933 - accuracy: 0.5862 - val_loss: 1.1649 - val_accuracy: 0.5488\n",
      "Epoch 19/200\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 1.0959 - accuracy: 0.5857 - val_loss: 1.2133 - val_accuracy: 0.5379\n",
      "Epoch 20/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0937 - accuracy: 0.5848 - val_loss: 1.1932 - val_accuracy: 0.5519\n",
      "Epoch 21/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0920 - accuracy: 0.5893 - val_loss: 1.1870 - val_accuracy: 0.5477\n",
      "Epoch 22/200\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 1.0962 - accuracy: 0.5830 - val_loss: 1.2675 - val_accuracy: 0.5338\n",
      "Epoch 23/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0969 - accuracy: 0.5838 - val_loss: 1.1529 - val_accuracy: 0.5597\n",
      "Epoch 24/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0972 - accuracy: 0.5855 - val_loss: 1.1453 - val_accuracy: 0.5670\n",
      "Epoch 25/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0920 - accuracy: 0.5849 - val_loss: 1.1268 - val_accuracy: 0.5723\n",
      "Epoch 26/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0931 - accuracy: 0.5860 - val_loss: 1.1314 - val_accuracy: 0.5720\n",
      "Epoch 27/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0909 - accuracy: 0.5829 - val_loss: 1.1901 - val_accuracy: 0.5547\n",
      "Epoch 28/200\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 1.0972 - accuracy: 0.5840 - val_loss: 1.1495 - val_accuracy: 0.5525\n",
      "Epoch 29/200\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 1.0910 - accuracy: 0.5877 - val_loss: 1.1444 - val_accuracy: 0.5597\n",
      "Epoch 30/200\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 1.0894 - accuracy: 0.5853 - val_loss: 1.2288 - val_accuracy: 0.5402\n",
      "Epoch 31/200\n",
      "448/448 [==============================] - 29s 64ms/step - loss: 1.0863 - accuracy: 0.5901 - val_loss: 1.1456 - val_accuracy: 0.5681\n",
      "Epoch 32/200\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 1.0941 - accuracy: 0.5832 - val_loss: 1.2043 - val_accuracy: 0.5396\n",
      "Epoch 33/200\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 1.0876 - accuracy: 0.5860 - val_loss: 1.1638 - val_accuracy: 0.5572\n",
      "Epoch 34/200\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 1.0875 - accuracy: 0.5876 - val_loss: 1.1971 - val_accuracy: 0.5399\n",
      "Epoch 35/200\n",
      "448/448 [==============================] - 29s 64ms/step - loss: 1.0842 - accuracy: 0.5883 - val_loss: 1.1744 - val_accuracy: 0.5552\n",
      "Epoch 36/200\n",
      "448/448 [==============================] - 29s 64ms/step - loss: 1.0843 - accuracy: 0.5903 - val_loss: 1.1655 - val_accuracy: 0.5516\n",
      "Epoch 37/200\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 1.0912 - accuracy: 0.5866 - val_loss: 1.1376 - val_accuracy: 0.5636\n",
      "Epoch 38/200\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 1.0886 - accuracy: 0.5898 - val_loss: 1.1630 - val_accuracy: 0.5572\n",
      "Epoch 39/200\n",
      "448/448 [==============================] - 29s 64ms/step - loss: 1.0892 - accuracy: 0.5878 - val_loss: 1.1545 - val_accuracy: 0.5639\n",
      "Epoch 40/200\n",
      "448/448 [==============================] - 29s 64ms/step - loss: 1.0855 - accuracy: 0.5861 - val_loss: 1.1588 - val_accuracy: 0.5617\n",
      "Epoch 41/200\n",
      "448/448 [==============================] - 29s 64ms/step - loss: 1.0780 - accuracy: 0.5880 - val_loss: 1.1657 - val_accuracy: 0.5592\n",
      "Epoch 42/200\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 1.0801 - accuracy: 0.5915 - val_loss: 1.1993 - val_accuracy: 0.5466\n",
      "Epoch 43/200\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 1.0847 - accuracy: 0.5879 - val_loss: 1.1457 - val_accuracy: 0.5611\n",
      "Epoch 44/200\n",
      "448/448 [==============================] - 31s 68ms/step - loss: 1.0840 - accuracy: 0.5880 - val_loss: 1.1589 - val_accuracy: 0.5622\n",
      "Epoch 45/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0770 - accuracy: 0.5934 - val_loss: 1.1529 - val_accuracy: 0.5583\n",
      "Epoch 46/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0835 - accuracy: 0.5875 - val_loss: 1.1609 - val_accuracy: 0.5656\n",
      "Epoch 47/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0750 - accuracy: 0.5929 - val_loss: 1.1708 - val_accuracy: 0.5580\n",
      "Epoch 48/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0773 - accuracy: 0.5898 - val_loss: 1.1498 - val_accuracy: 0.5639\n",
      "Epoch 49/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0705 - accuracy: 0.5953 - val_loss: 1.2076 - val_accuracy: 0.5491\n",
      "Epoch 50/200\n",
      "448/448 [==============================] - 31s 69ms/step - loss: 1.0769 - accuracy: 0.5930 - val_loss: 1.1422 - val_accuracy: 0.5684\n",
      "Epoch 51/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0768 - accuracy: 0.5938 - val_loss: 1.1639 - val_accuracy: 0.5530\n",
      "Epoch 52/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0717 - accuracy: 0.5922 - val_loss: 1.1951 - val_accuracy: 0.5463\n",
      "Epoch 53/200\n",
      "448/448 [==============================] - 31s 68ms/step - loss: 1.0752 - accuracy: 0.5921 - val_loss: 1.1291 - val_accuracy: 0.5809\n",
      "Epoch 54/200\n",
      "448/448 [==============================] - 31s 68ms/step - loss: 1.0706 - accuracy: 0.5958 - val_loss: 1.1421 - val_accuracy: 0.5706\n",
      "Epoch 55/200\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 1.0694 - accuracy: 0.5960 - val_loss: 1.1551 - val_accuracy: 0.5698\n",
      "Epoch 56/200\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 1.0721 - accuracy: 0.5942 - val_loss: 1.1646 - val_accuracy: 0.5622\n",
      "Epoch 57/200\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 1.0688 - accuracy: 0.5967 - val_loss: 1.1456 - val_accuracy: 0.5689\n",
      "Epoch 58/200\n",
      "448/448 [==============================] - 31s 68ms/step - loss: 1.0714 - accuracy: 0.5927 - val_loss: 1.1437 - val_accuracy: 0.5633\n",
      "Epoch 59/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0660 - accuracy: 0.5961 - val_loss: 1.1679 - val_accuracy: 0.5580\n",
      "Epoch 60/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0709 - accuracy: 0.5930 - val_loss: 1.1488 - val_accuracy: 0.5706\n",
      "Epoch 61/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0704 - accuracy: 0.5942 - val_loss: 1.1435 - val_accuracy: 0.5711\n",
      "Epoch 62/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0691 - accuracy: 0.5941 - val_loss: 1.1975 - val_accuracy: 0.5541 1.0696 - accuracy: 0.59\n",
      "Epoch 63/200\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 1.0725 - accuracy: 0.5957 - val_loss: 1.1379 - val_accuracy: 0.5714\n",
      "Epoch 64/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0603 - accuracy: 0.5990 - val_loss: 1.1232 - val_accuracy: 0.5751\n",
      "Epoch 65/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0681 - accuracy: 0.5956 - val_loss: 1.1411 - val_accuracy: 0.5647\n",
      "Epoch 66/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0643 - accuracy: 0.5991 - val_loss: 1.1460 - val_accuracy: 0.5619\n",
      "Epoch 67/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0687 - accuracy: 0.5945 - val_loss: 1.1405 - val_accuracy: 0.5723\n",
      "Epoch 68/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0645 - accuracy: 0.5966 - val_loss: 1.1420 - val_accuracy: 0.5597\n",
      "Epoch 69/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0718 - accuracy: 0.5939 - val_loss: 1.1697 - val_accuracy: 0.5530\n",
      "Epoch 70/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0701 - accuracy: 0.5950 - val_loss: 1.1958 - val_accuracy: 0.5427\n",
      "Epoch 71/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0644 - accuracy: 0.5938 - val_loss: 1.1211 - val_accuracy: 0.5762\n",
      "Epoch 72/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0610 - accuracy: 0.5983 - val_loss: 1.1247 - val_accuracy: 0.5742\n",
      "Epoch 73/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0572 - accuracy: 0.6001 - val_loss: 1.1462 - val_accuracy: 0.5698\n",
      "Epoch 74/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0559 - accuracy: 0.5984 - val_loss: 1.1509 - val_accuracy: 0.5603\n",
      "Epoch 75/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0604 - accuracy: 0.5994 - val_loss: 1.1405 - val_accuracy: 0.5625\n",
      "Epoch 76/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0578 - accuracy: 0.6009 - val_loss: 1.1274 - val_accuracy: 0.5684\n",
      "Epoch 77/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0651 - accuracy: 0.5994 - val_loss: 1.1568 - val_accuracy: 0.5619\n",
      "Epoch 78/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0568 - accuracy: 0.6004 - val_loss: 1.1349 - val_accuracy: 0.5739\n",
      "Epoch 79/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0603 - accuracy: 0.5977 - val_loss: 1.1864 - val_accuracy: 0.5421\n",
      "Epoch 80/200\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 1.0674 - accuracy: 0.5943 - val_loss: 1.1967 - val_accuracy: 0.5592\n",
      "Epoch 81/200\n",
      "448/448 [==============================] - 29s 64ms/step - loss: 1.0585 - accuracy: 0.6019 - val_loss: 1.1434 - val_accuracy: 0.5725\n",
      "Epoch 82/200\n",
      "448/448 [==============================] - 29s 64ms/step - loss: 1.0602 - accuracy: 0.5991 - val_loss: 1.1127 - val_accuracy: 0.5896 loss: 1.0586 - accuracy - ETA: \n",
      "Epoch 83/200\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 1.0501 - accuracy: 0.6001 - val_loss: 1.2847 - val_accuracy: 0.5209\n",
      "Epoch 84/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0564 - accuracy: 0.6026 - val_loss: 1.1496 - val_accuracy: 0.5661\n",
      "Epoch 85/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0592 - accuracy: 0.5994 - val_loss: 1.1584 - val_accuracy: 0.5594\n",
      "Epoch 86/200\n",
      "448/448 [==============================] - 31s 68ms/step - loss: 1.0557 - accuracy: 0.6004 - val_loss: 1.2021 - val_accuracy: 0.5541\n",
      "Epoch 87/200\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 1.0592 - accuracy: 0.5993 - val_loss: 1.1306 - val_accuracy: 0.5734\n",
      "Epoch 88/200\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 1.0548 - accuracy: 0.6019 - val_loss: 1.1881 - val_accuracy: 0.5505\n",
      "Epoch 89/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0572 - accuracy: 0.5981 - val_loss: 1.0998 - val_accuracy: 0.5818\n",
      "Epoch 90/200\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 1.0564 - accuracy: 0.5969 - val_loss: 1.1293 - val_accuracy: 0.5767\n",
      "Epoch 91/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0494 - accuracy: 0.6041 - val_loss: 1.1361 - val_accuracy: 0.5751\n",
      "Epoch 92/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0526 - accuracy: 0.6049 - val_loss: 1.1656 - val_accuracy: 0.5658\n",
      "Epoch 93/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0522 - accuracy: 0.6013 - val_loss: 1.1696 - val_accuracy: 0.5569\n",
      "Epoch 94/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0511 - accuracy: 0.6004 - val_loss: 1.1200 - val_accuracy: 0.5711\n",
      "Epoch 95/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0535 - accuracy: 0.6011 - val_loss: 1.1195 - val_accuracy: 0.5829\n",
      "Epoch 96/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0468 - accuracy: 0.6056 - val_loss: 1.1472 - val_accuracy: 0.5614\n",
      "Epoch 97/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0535 - accuracy: 0.6002 - val_loss: 1.1439 - val_accuracy: 0.5647\n",
      "Epoch 98/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0536 - accuracy: 0.6013 - val_loss: 1.1213 - val_accuracy: 0.5739\n",
      "Epoch 99/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0443 - accuracy: 0.6018 - val_loss: 1.2002 - val_accuracy: 0.5488\n",
      "Epoch 100/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0402 - accuracy: 0.6048 - val_loss: 1.1349 - val_accuracy: 0.5773\n",
      "Epoch 101/200\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0509 - accuracy: 0.6031 - val_loss: 1.1485 - val_accuracy: 0.5605\n",
      "Epoch 102/200\n",
      "448/448 [==============================] - 30s 68ms/step - loss: 1.0483 - accuracy: 0.6011 - val_loss: 1.2042 - val_accuracy: 0.5379\n",
      "Epoch 103/200\n",
      "232/448 [==============>...............] - ETA: 14s - loss: 1.0334 - accuracy: 0.6114"
     ]
    }
   ],
   "source": [
    "history = train_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 4s 74ms/step - loss: 1.7269 - sparse_categorical_accuracy: 0.4851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.726860144682098, 0.48509336]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_labeled_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
